{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction of confused adjectives and adverbs\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Non-native speakers often find it difficult *(or is it difficultly?)* to learn the proper usage of adverbs and adjectives in English:\n",
    "* _Do I speak English **fluent** or **fluently**?_\n",
    "* _Why do I look **nice** but talk **nicely**?_\n",
    "* _Why is it that my car both is **fast** and goes **fast**?_\n",
    "* _Why can you both **remote control** and **remotely control** something?_\n",
    "\n",
    "In this project, we will develop a simple classifier that decides whether an adjective or an adverb is needed in a certain context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we change adjectives to adverbs and vice versa?\n",
    "\n",
    "In English, adverbs are formed from adjectives by adding \"-ly\": free => free**ly**.\n",
    "\n",
    "However, there are exceptions to that:\n",
    "- _responsib**le** => responsib**ly**_\n",
    "- _angr**y** => angr**ily**_\n",
    "- _idiot**ic** => idiot**ically**_\n",
    "- _full => full**y**_\n",
    "- _ugly => in an ugly way?_\n",
    "- _**good** => **well**_\n",
    "- _**hard** => **hard**; **hardly** has a different meaning_\n",
    "- _**state-of-the-art** => **?**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import json\n",
    "import en_core_web_md\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Doc\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of adjectives: 61768\n",
      "Total number of adverbs: 10791\n"
     ]
    }
   ],
   "source": [
    "# Read all adjectives and adverbs that are present in English Wiktionary\n",
    "# https://en.wiktionary.org/wiki/Wiktionary:Main_Page\n",
    "\n",
    "with open(\"data/adjectives.txt\", \"r\") as f:\n",
    "    ADJ = set(line.strip() for line in f.readlines())\n",
    "\n",
    "with open(\"data/adverbs.txt\", \"r\") as f:\n",
    "    ADV = set(line.strip() for line in f.readlines())\n",
    "    \n",
    "print(\"Total number of adjectives:\", len(ADJ))\n",
    "print(\"Total number of adverbs:\", len(ADV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheep-headed       => None\n",
      "bugproof           => None\n",
      "exigible           => None\n",
      "zygomycotic        => None\n",
      "hysteretical       => hysteretically\n",
      "slovenian          => None\n",
      "representative     => representatively\n",
      "underfurnished     => None\n",
      "rampartlike        => None\n",
      "geyserlike         => None\n",
      "boilerplate        => None\n",
      "ekphrastic         => None\n",
      "canescent          => None\n",
      "nonfungicidal      => None\n",
      "orbitosphenoid     => None\n",
      "inefficacious      => inefficaciously\n",
      "herolike           => None\n",
      "immunodominant     => None\n",
      "ununitable         => None\n",
      "multicritical      => None\n"
     ]
    }
   ],
   "source": [
    "# Learn to transform adjectives to adverbs\n",
    "\n",
    "def transform_adj_to_adv(adjective):\n",
    "    \"\"\"\n",
    "    Convert an adjective to the corresponding adverb.\n",
    "    :param adjective: string (adjective)\n",
    "    :return: string (adverb) or None\n",
    "    \"\"\"\n",
    "\n",
    "    # friendly\n",
    "    if adjective.endswith(\"ly\"):\n",
    "        return None\n",
    "    # hard\n",
    "    if adjective in ADV:\n",
    "        return adjective\n",
    "\n",
    "    # exceptions\n",
    "    elif adjective == \"good\":\n",
    "        return \"well\"\n",
    "    elif adjective in [\"whole\", \"true\"]:\n",
    "        return adjective[:-1] + \"ly\"\n",
    "\n",
    "    # responsible => responsibly\n",
    "    elif adjective.endswith(\"le\") and adjective != \"sole\":\n",
    "        adverb = adjective[:-1] + \"y\"\n",
    "    # angry => angrily\n",
    "    elif adjective.endswith(\"y\") and adjective != \"shy\":\n",
    "        adverb = adjective[:-1] + \"ily\"\n",
    "    # idiotic => idiotically\n",
    "    elif adjective.endswith(\"ic\"):\n",
    "        adverb = adjective + \"ally\"\n",
    "    # full => fully\n",
    "    elif adjective.endswith(\"ll\"):\n",
    "        adverb = adjective + \"y\"\n",
    "    # free => freely\n",
    "    else:\n",
    "        adverb = adjective + \"ly\"\n",
    "\n",
    "    # check for validity\n",
    "    return adverb if adverb in ADV else None\n",
    "\n",
    "for i in range(20):\n",
    "    word = random.sample(ADJ, 1)[0]\n",
    "    print(\"{:18} => {}\".format(word, transform_adj_to_adv(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of adjectives: 61768\n",
      "Total number of adverbs: 10791\n",
      "Number of adjectives that can be transformed to adverbs: 8330\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for adjective-adverb transformation\n",
    "\n",
    "adj_to_adv, adv_to_adj = dict(), dict()\n",
    "\n",
    "for adj in ADJ:\n",
    "    adv = transform_adj_to_adv(adj)\n",
    "    if adv and adv != adj:\n",
    "        adj_to_adv[adj] = adv\n",
    "        adv_to_adj[adv] = adj\n",
    "\n",
    "print(\"Total number of adjectives:\", len(ADJ))\n",
    "print(\"Total number of adverbs:\", len(ADV))\n",
    "print(\"Number of adjectives that can be transformed to adverbs:\",\n",
    "      len(adj_to_adv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features distinguish adjectives from adverbs?\n",
    "\n",
    "Hypotheses:\n",
    "- left and right context\n",
    "- type of relation to the head\n",
    "- dependants (if there are any)\n",
    "- the word itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded in 18 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy models\n",
    "\n",
    "start = time.time()\n",
    "nlp = en_core_web_md.load(disable=['ner'])\n",
    "print(\"Models loaded in\", round(time.time() - start), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of speech:\n",
      "She_PRP was_VBD completely_RB natural_JJ and_CC unaffected_JJ by_IN the_DT attention_NN ._.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1150\" height=\"302.0\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">She</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">completely</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">unaffected</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">attention</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M180,167.0 C180,57.0 375.0,57.0 375.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M375.0,169.0 L383.0,157.0 367.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,169.0 L488.0,157.0 472.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M400,167.0 C400,57.0 595.0,57.0 595.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595.0,169.0 L603.0,157.0 587.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700.0,169.0 L708.0,157.0 692.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M840,167.0 C840,112.0 920.0,112.0 920.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,169.0 L832,157.0 848,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M730,167.0 C730,57.0 925.0,57.0 925.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,169.0 L933.0,157.0 917.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M180,167.0 C180,2.0 1040.0,2.0 1040.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1040.0,169.0 L1048.0,157.0 1032.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse sentences with adjective and adverb\n",
    "\n",
    "# sentence = nlp(\"The soup smells good.\")\n",
    "# print(\"Parts of speech:\")\n",
    "# print(\" \".join(\"{}_{}\".format(token.text, token.tag_) for token in sentence))\n",
    "# displacy.render(sentence, style='dep', options={\"collapse_punct\": False, \"distance\": 110}, jupyter=True)\n",
    "\n",
    "# sentence = nlp(\"He smells the hot soup carefully.\")\n",
    "# print(\"Parts of speech:\")\n",
    "# print(\" \".join(\"{}_{}\".format(token.text, token.tag_) for token in sentence))\n",
    "# displacy.render(sentence, style='dep', options={\"collapse_punct\": False, \"distance\": 110}, jupyter=True)\n",
    "\n",
    "# sentence = nlp(\"Mary naturally and quickly became part of our family.\")\n",
    "# print(\"Parts of speech:\")\n",
    "# print(\" \".join(\"{}_{}\".format(token.text, token.tag_) for token in sentence))\n",
    "# displacy.render(sentence, style='dep', options={\"collapse_punct\": False, \"distance\": 110}, jupyter=True)\n",
    "\n",
    "sentence = nlp(\"She was completely natural and unaffected by the attention.\")\n",
    "print(\"Parts of speech:\")\n",
    "print(\" \".join(\"{}_{}\".format(token.text, token.tag_) for token in sentence))\n",
    "displacy.render(sentence, style='dep', options={\"collapse_punct\": False, \"distance\": 110}, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect features\n",
    "\n",
    "def feature_extractor(sentence, ind):\n",
    "    \"\"\"\n",
    "    Collect features for the INDth token in SENTENCE.\n",
    "    \n",
    "    :param sentence: Doc, a parsed sentence\n",
    "    :param ind: the index of the token\n",
    "    :return: a feature dictionary\n",
    "    \"\"\"\n",
    "    token = sentence[ind]\n",
    "    features = dict()\n",
    "    # context\n",
    "    features[\"w-1\"] = sentence[ind-1].text if ind > 0 else \"NONE\"\n",
    "    features[\"w+1\"] = sentence[ind+1].text if ind < (len(sentence) - 1) else \"NONE\"\n",
    "    # children\n",
    "    for child in token.children:\n",
    "        features[child.dep_] = child.text\n",
    "    # if we collect features for an adjective\n",
    "    if token.tag_ == \"JJ\" and token.text in adj_to_adv:\n",
    "        features[\"adj\"] = token.text\n",
    "        features[\"adv\"] = adj_to_adv[token.text]\n",
    "        features[\"adj_head\"] = token.dep_ + \"_\" + token.head.lemma_\n",
    "        alt_sentence = nlp(\" \".join([t.text for t in sentence[:ind]]\n",
    "                                    + [features[\"adv\"]] +\n",
    "                                    [t.text for t in sentence[ind + 1:]]))\n",
    "        features[\"adv_head\"] = alt_sentence[ind].dep_ + \"_\" + \\\n",
    "                               alt_sentence[ind].head.lemma_\n",
    "    # if we collect features for an adverb\n",
    "    elif token.tag_ == \"RB\" and token.text in adv_to_adj:\n",
    "        features[\"adv\"] = token.text\n",
    "        features[\"adj\"] = adv_to_adj[token.text]\n",
    "        features[\"adv_head\"] = token.dep_ + \"_\" + token.head.lemma_\n",
    "        alt_sentence = nlp(\" \".join([t.text for t in sentence[:ind]]\n",
    "                                    + [features[\"adj\"]] +\n",
    "                                    [t.text for t in sentence[ind + 1:]]))\n",
    "        features[\"adj_head\"] = alt_sentence[ind].dep_ + \"_\" + \\\n",
    "                               alt_sentence[ind].head.lemma_\n",
    "    else:\n",
    "        return None\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word in question: good\n",
      "{'w-1': 'smells', 'w+1': '.', 'adj': 'good', 'adv': 'well', 'adj_head': 'acomp_smell', 'adv_head': 'advmod_smell'}\n",
      "Label: ADJ\n",
      "\n",
      "Word in question: carefully\n",
      "{'w-1': 'soup', 'w+1': '.', 'adv': 'carefully', 'adj': 'careful', 'adv_head': 'advmod_smell', 'adj_head': 'advcl_smell'}\n",
      "Label: ADV\n",
      "\n",
      "Word in question: naturally\n",
      "{'w-1': 'Mary', 'w+1': 'and', 'cc': 'and', 'conj': 'quickly', 'adv': 'naturally', 'adj': 'natural', 'adv_head': 'advmod_become', 'adj_head': 'advmod_become'}\n",
      "Label: ADV\n",
      "\n",
      "Word in question: natural\n",
      "{'w-1': 'completely', 'w+1': 'and', 'advmod': 'completely', 'cc': 'and', 'conj': 'unaffected', 'adj': 'natural', 'adv': 'naturally', 'adj_head': 'acomp_be', 'adv_head': 'advmod_be'}\n",
      "Label: ADJ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect features for sample sentences\n",
    "\n",
    "corpus = [\"The soup smells good.\",\n",
    "          \"He smells the hot soup carefully.\",\n",
    "          \"Mary naturally and quickly became part of our family.\",\n",
    "          \"She was completely natural and unaffected by the attention.\"]\n",
    "data, labels = [], []\n",
    "for sentence in corpus:\n",
    "    sentence = nlp(sentence)\n",
    "    for token in sentence:\n",
    "        if token.tag_ in [\"JJ\", \"RB\"] and token.head.tag_.startswith(\"VB\"):\n",
    "            features = feature_extractor(sentence, token.i)\n",
    "            data.append(features)\n",
    "            labels.append(token.pos)\n",
    "            print(\"Word in question:\", token.text)\n",
    "            print(features)\n",
    "            print(\"Label:\", token.pos_)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize features for sample sentences\n",
    "\n",
    "vec = DictVectorizer()\n",
    "x = vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features:\n",
      "['adj=careful', 'adj=good', 'adj=natural', 'adj_head=acomp_be', 'adj_head=acomp_smell', 'adj_head=advcl_smell', 'adj_head=advmod_become', 'adv=carefully', 'adv=naturally', 'adv=well', 'adv_head=advmod_be', 'adv_head=advmod_become', 'adv_head=advmod_smell', 'advmod=completely', 'cc=and', 'conj=quickly', 'conj=unaffected', 'w+1=.', 'w+1=and', 'w-1=Mary', 'w-1=completely', 'w-1=smells', 'w-1=soup']\n",
      "\n",
      "Total number of features:  23\n"
     ]
    }
   ],
   "source": [
    "# The full feature set\n",
    "\n",
    "print(\"All features:\")\n",
    "print(vec.get_feature_names())\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting sparse matrix:\n",
      "[[0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The resulting sparse matrix\n",
    "\n",
    "print(\"The resulting sparse matrix:\")\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do we get data?\n",
    "\n",
    "Possible sources of data are:\n",
    "- learner corpora (e.g., [lang-8](http://cl.naist.jp/nldata/lang-8/), [NUCLE](http://www.comp.nus.edu.sg/~nlp/conll14st.html))\n",
    "- use grammatically correct data\n",
    "- use crowdsourcing platform (e.g, [MTurk](https://www.mturk.com/) or [CrowdFlower](https://www.figure-eight.com/)) or linguists (e.g., [Appen](https://appen.com/)) to annotate data\n",
    "\n",
    "But suppose we don't have any money or time :trollface: Thus, we will be using a corpus of allegedly correct English - [The Blog Authorship Corpus](http://u.cs.biu.ac.il/~koppel/BlogCorpus.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: ['Wow', ',', 'that', 'really', 'does', 'make', 'me', 'sad', '.', ' ']\n",
      "ind: 7\n",
      "label: ADJ\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/adj_vs_adv_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for k, v in data[100].items():\n",
    "    print(k + \":\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17571 17571\n"
     ]
    }
   ],
   "source": [
    "# Collect features from our data set\n",
    "\n",
    "x_features, y = [], []\n",
    "for sample in data:\n",
    "    sentence = nlp(\" \".join(sample[\"sentence\"]))\n",
    "    features = feature_extractor(sentence, sample[\"ind\"])\n",
    "    if features:\n",
    "        x_features.append(features)\n",
    "        y.append(sample[\"label\"])\n",
    "\n",
    "print(len(x_features), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w-1': 'completely', 'w+1': ',', 'advmod': 'completely', 'adj': 'boring', 'adv': 'boringly', 'adj_head': 'acomp_be', 'adv_head': 'acomp_be'} ADJ\n",
      "\n",
      "Total number of features:  14196\n"
     ]
    }
   ],
   "source": [
    "# Vectorize data\n",
    "\n",
    "print(x_features[100], y[100])\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "x = vectorizer.fit_transform(x_features)\n",
    "print(\"\\nTotal number of features: \", len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.95, 0.94]\n",
      "Recall: [0.94, 0.96]\n",
      "F-score: [0.94, 0.95]\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "\n",
    "lrc = LogisticRegression(random_state=42)\n",
    "lrc.fit(x_train, y_train)\n",
    "predicted = lrc.predict(x_test)\n",
    "prec, rec, fscore, sup = precision_recall_fscore_support(y_test, predicted, labels=['ADJ', 'ADV'])\n",
    "print(\"Precision:\", [round(p, 2) for p in prec])\n",
    "print(\"Recall:\", [round(r, 2) for r in rec])\n",
    "print(\"F-score:\", [round(f, 2) for f in fscore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: You have successful completed the project .\n",
      "You have {successful=>successfully} completed the project .\n",
      "\n",
      "Input: I am busy talking to my friend.\n",
      "No errors found.\n",
      "\n",
      "Input: I am emotional talking to my friend.\n",
      "I am {emotional=>emotionally} talking to my friend .\n",
      "\n",
      "Input: The soup smells good .\n",
      "No errors found.\n",
      "\n",
      "Input: He smells the hot soup careful .\n",
      "He smells the hot soup {careful=>carefully} .\n",
      "\n",
      "Input: Mary natural and quickly became part of our family.\n",
      "Mary {natural=>naturally} and quickly became part of our family .\n",
      "\n",
      "Input: She was completely natural and unaffected by the attention.\n",
      "No errors found.\n"
     ]
    }
   ],
   "source": [
    "def is_adj_correct(raw_sentence):\n",
    "    sentence = nlp(raw_sentence)\n",
    "    print(\"Input:\", raw_sentence)\n",
    "    for ind in range(len(sentence)):\n",
    "        token = sentence[ind]\n",
    "        if token.tag_ == \"JJ\" and token.head.tag_.startswith(\"VB\"):\n",
    "            features = feature_extractor(sentence, ind)\n",
    "            predicted_pos = lrc.predict(vectorizer.transform(features))\n",
    "            if predicted_pos == \"ADJ\":\n",
    "                print(\"No errors found.\")\n",
    "                return\n",
    "            else:\n",
    "                print(\" \".join([t.text for t in sentence[:ind]]\n",
    "                                + [\"{\" + sentence[ind].text + \"=>\" + adj_to_adv[sentence[ind].text] + \"}\"] +\n",
    "                                [t.text for t in sentence[ind+1:]]))\n",
    "                return\n",
    "    print(\"No errors found.\")\n",
    "    return\n",
    "\n",
    "is_adj_correct(\"You have successful completed the project .\")\n",
    "print(\"\")\n",
    "is_adj_correct(\"I am busy talking to my friend.\")\n",
    "print(\"\")\n",
    "is_adj_correct(\"I am emotional talking to my friend.\")\n",
    "print(\"\")\n",
    "is_adj_correct(\"The soup smells good .\")\n",
    "print(\"\")\n",
    "is_adj_correct(\"He smells the hot soup careful .\")\n",
    "print(\"\")\n",
    "is_adj_correct(\"Mary natural and quickly became part of our family.\")\n",
    "print(\"\")\n",
    "is_adj_correct(\"She was completely natural and unaffected by the attention.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
